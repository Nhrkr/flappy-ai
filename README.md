# To-do

Research existing approaches

Decide which approach(s) to take

Choose Flappy Bird engine to use

1. pygame version https://github.com/sourabhv/FlapPyBird

~~2. MelonJS https://github.com/ellisonleao/clumsy-bird

will have to install node and grunt for it
~3. ANDEngine (Java) https://github.com/deano2390/OpenFlappyBird~

~~4. HTML5 https://github.com/nebez/floppybird

based on html canvas, might have to use js for later traning or any changes

Start coding

# Links

https://github.com/SarvagyaVaish/FlappyBirdRL
Uses ~reinforcement~ Q-learning

https://pastebin.com/ZZmSNaHX
Seth Bling's MarI/O Code

http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf
NEAT paper (used in Seth Bling's implementation)

https://github.com/mdibaiee/flappy-es
Uses evolution strategies, not sure which flappy bird engine used

https://blog.openai.com/evolution-strategies/
Reference for evolution strategies

https://github.com/chncyhn/flappybird-qlearning-bot
Uses Q-learning, uses sarvaigyavaish's base model, sourabhv's pygame Flappy Bird

https://github.com/mihaibivol/Q-learning-tic-tac-toec
Tic-tac-toe using Q-learning

https://github.com/yenchenlin/DeepLearningFlappyBird
Uses deep Q-learning to play Flappy Bird

https://github.com/asrivat1/DeepLearningVideoGames
Using Deep Q Networks to Learn Video Game Strategies

https://tonypoer.io/2016/12/15/making-an-ai-to-play-flappy-bird-w-q-learning/
Blog which describes using Q-learning to learn to play Flappy Bird

http://mnemstudio.org/path-finding-q-learning-tutorial.htm
Tutorial for Q-learning by path-finding
